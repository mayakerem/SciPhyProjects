{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Impact of Architecture On ANN Accuracy ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Course: Scientific Computation with Python\n",
    "\n",
    "By: Maya Kerem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook')\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Flatten\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction:\n",
    "    \n",
    "This project will investigate the​ impact of an ANN architecture on the accuracy of ANN. ​The architecture will vary in the number of hidden layers it will have and the type of hidden layer. The types of hidden layers that will be investigated are Dense Layer, Convolutional Layers, and Pool Layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Teacher Notes:_ As the number of layers / neurons increase, you expect to see higher accuracy; but you would also probably need to increase training time, both in seconds and in number of epochs. it may be the case that if you keep training time constant, then your hypothesis fails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Data:\n",
    "An open question regarding which dataset will be used. Initial iteration will run on ​Churn Data.​ If time permits, I will revise the project and perform a second iteration, where I will create my\n",
    "own dataset that will be generated using a simulation methodology (such as Lotka–Volterra)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Churn_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          2       0.00              1          1               1   \n",
       "1          1   83807.86              1          0               1   \n",
       "2          8  159660.80              3          1               0   \n",
       "3          1       0.00              2          0               0   \n",
       "4          2  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df.columns))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 7 is out of bounds for axis 0 with size 7",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-f8d3ca912bdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 7 is out of bounds for axis 0 with size 7"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 14 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(7,2)\n",
    "for i,feature in zip(range(14),df.columns):\n",
    "    if i < 6:\n",
    "        axs[i][0] = plt.hist(df[feature])\n",
    "    else:\n",
    "        axs[i][1] = plt.hist(df[feature])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Neural Network Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models and methods that will be applied are going to based on the Keras library. Firstly, the model will be made of the Keras ​Sequential object. Then a model summary will be composed for each ANN. The model will then be compiled and fit the data. Lastly, the effectiveness of the architecture will be examined by​ model.evalaute ​method.\n",
    "These methods will be used and obtained from Keras’s Library. Moreover, this library will provide the different types of layers: Dense layer, Conv1D layer, Conv2D layer, Conv3D layer, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# this code is required for Ex 1\n",
    "def display_image(im):\n",
    "    plt.imshow(im.reshape((28, 28)), cmap='gray_r')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "def fully_connected(ninputs, noutputs):\n",
    "    boundary = np.sqrt(6 / (ninputs + noutputs))\n",
    "    return np.random.uniform(-boundary, boundary, size=(ninputs, noutputs))\n",
    "\n",
    "def softmax(x):\n",
    "    expx = np.exp(x - x.max(axis=1, keepdims=True))\n",
    "    return expx / expx.sum(axis=1, keepdims=True)\n",
    "\n",
    "def accuracy(Yhat, Y):\n",
    "    return (Y.argmax(axis=1) == Yhat.argmax(axis=1)).mean()\n",
    "\n",
    "def cross_entropy(Yhat, Y):\n",
    "    ylogy = Y * np.log(Yhat)\n",
    "    return -ylogy.sum()\n",
    "\n",
    "def ReLU(X):\n",
    "    return np.maximum(X, 0)\n",
    "\n",
    "def dReLU(X):\n",
    "    return (X > 0).astype(float)\n",
    "\n",
    "def drop(X, keep_prob=1):\n",
    "    if keep_prob < 1:\n",
    "        X = X.copy() # we don't want to change X\n",
    "        keeps = np.random.rand(X.shape[1]) < keep_prob\n",
    "        # X.shape is (nsamples, nfeatures)\n",
    "        X[:, ~keeps] = 0 # ignore\n",
    "        X[:, keeps] *= (1/keep_prob) # normalize\n",
    "    return X\n",
    "\n",
    "def predict(Ws, X):\n",
    "    if X.ndim == 1:\n",
    "        X = X.reshape((1, -1))\n",
    "    return feed_forward(Ws, X, keep_prob=1)[-1]\n",
    "\n",
    "def display_prediction(idx):\n",
    "    prediction = predict(Ws, X_test[idx, :]).argmax()\n",
    "    print(prediction)\n",
    "    return display_image(X_test[idx])\n",
    "\n",
    "def loss(Ws, X, Y):\n",
    "    Yhat = predict(Ws, X)\n",
    "    return cross_entropy(Yhat, Y)\n",
    "\n",
    "def gradient_check(Ws, X, Y, Δ=1e-5):\n",
    "    dWs = back_propagation(Ws, X, Y, keep_prob=1)\n",
    "    Ws_ = [W.copy() for W in Ws]\n",
    "\n",
    "    for i, (W_, dW_) in enumerate(zip(Ws_, dWs)):\n",
    "        print('W{}'.format(i+1))\n",
    "        for i in range(W_.shape[0]):\n",
    "            for j in range(W_.shape[1]):\n",
    "                dw = dW_[i, j]\n",
    "                W_[i,j] += Δ\n",
    "                loss1 = loss(Ws_, X, Y)\n",
    "                W_[i,j] -= 2*Δ\n",
    "                loss2 = loss(Ws_, X, Y)\n",
    "                W_[i,j] += Δ\n",
    "                dw_ = (loss1 - loss2) / (2 * Δ)\n",
    "                rel_error = abs(dw - dw_) / abs(dw + dw_)\n",
    "                if not np.isclose(dw_, dw):\n",
    "                    print(i, j, dw, dw_, rel_error)\n",
    "                    \n",
    "def average(prev, curr, β):\n",
    "    return [\n",
    "        β * p + (1 - β) * c\n",
    "        for p, c\n",
    "        in zip(prev, curr)\n",
    "    ]\n",
    "    \n",
    "class AdamOptimizer:\n",
    "    def __init__(self, α=0.001, β1=0.9, β2=0.999, ϵ=1e-8):\n",
    "        self.α = α\n",
    "        self.β1 = β1\n",
    "        self.β2 = β2\n",
    "        self.ϵ = ϵ\n",
    "        self.m = None\n",
    "        self.v = None\n",
    "        self.t = 0\n",
    "\n",
    "    def send(self, gradients):\n",
    "        if self.m is None:\n",
    "            self.m = [0] * len(gradients)\n",
    "        if self.v is None:\n",
    "            self.v = [0] * len(gradients)\n",
    "\n",
    "        self.t += 1\n",
    "        αt = self.α * np.sqrt(1 - self.β2**self.t) / (1 - self.β1**self.t)\n",
    "        self.m = average(self.m, gradients, self.β1)        \n",
    "        self.v = average(self.v, (g*g for g in gradients), self.β2)\n",
    "\n",
    "        updates = [-αt * mi / (np.sqrt(vi) + self.ϵ) for mi, vi in zip(self.m, self.v)]\n",
    "        for upd in updates:\n",
    "            assert np.isfinite(upd).all()\n",
    "        return updates\n",
    "    \n",
    "def trainer(Ws, X, Y, optimizer, batch_size=50, keep_prob=1):    \n",
    "    nsamples = X.shape[0]\n",
    "    batch = 0\n",
    "    while True:\n",
    "        # get next batch\n",
    "        start = (batch * batch_size) % nsamples\n",
    "        stop = start + batch_size\n",
    "        batch_idx = range(start, stop)\n",
    "        X_, Y_ = X[batch_idx, :], Y[batch_idx, :]\n",
    "        \n",
    "        gradients = back_propagation(Ws, X_, Y_, keep_prob=keep_prob) # calculate gradients\n",
    "        \n",
    "        ΔWs = optimizer.send(gradients) # calculate updates\n",
    "        \n",
    "        for W, ΔW in zip(Ws, ΔWs): # apply updates\n",
    "            W += ΔW\n",
    "            \n",
    "        batch += 1\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-f5368bdc36ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnsamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# X_train = X_train.reshape(nsamples, nfeatures)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "###\n",
    "(X_train, Y_train), (X_test, Y_test) = keras.datasets.mnist.load_data()\n",
    "nsamples, width, height = X_train.shape\n",
    "nfeatures = width * height\n",
    "X_train = X_train.reshape(nsamples, nfeatures)\n",
    "X_test = X_test.reshape(-1, nfeatures)\n",
    "Y_train = keras.utils.to_categorical(Y_train)\n",
    "Y_test = keras.utils.to_categorical(Y_test)\n",
    "ncats = Y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Accuracy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciPhy",
   "language": "python",
   "name": "sciphy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
